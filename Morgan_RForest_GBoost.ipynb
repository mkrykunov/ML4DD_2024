{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb56ee57-76ac-45db-a96c-b65b5c544417",
   "metadata": {},
   "source": [
    "# Machine Learning for Drug Discovery 2024\n",
    "### Solubility\n",
    "The code in this notebook is written to solve one of the problems from a hackathon at Machine Learning for Drug Discovery Summer School in Montreal in 2024. The benchmark is from polaris. Polaris is a hub for computational drug discovery benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09663de6-330c-4b0a-a0ec-24c462c10be8",
   "metadata": {},
   "source": [
    "First, we import necessary packages. You might need to install polaris\n",
    "\n",
    "**pip install polaris-lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b6f37c-e710-47d8-8579-0028c91bf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import polaris as po\n",
    "import numpy as np\n",
    "import datamol as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26c392-00d1-4ef8-92bd-8f70fc20f824",
   "metadata": {},
   "source": [
    "One of the benchmarks from the Polaris hub for the Log solubility problem containing 1578 training and 400 test points. It's a regression task. The info about this set can be found here: https://polarishub.io/benchmarks/polaris/adme-fang-solu-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93ac3a-34d1-4f6f-af78-45b30aee8ac4",
   "metadata": {},
   "source": [
    "Before loading you might need to register by running the following command\n",
    "\n",
    "**polaris login**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43f34e8-50c5-4771-94e6-03c60e917116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-09 18:34:48.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n",
      "\u001b[32m2024-07-09 18:34:48.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "benchmark1 = po.load_benchmark(\"polaris/adme-fang-solu-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c351c49-da16-47a6-9f24-7dc9ebf134b3",
   "metadata": {},
   "source": [
    "We will use Datamol's `dm.to_fp` to directly featurize the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cf48da-0d5e-4b2e-a2c8-4cb5dc4546c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "1.567849451\n",
      "(1578, 2048)\n",
      "(1578,)\n"
     ]
    }
   ],
   "source": [
    "train, test = benchmark1.get_train_test_split(featurization_fn = dm.to_fp)\n",
    "print (train.inputs[0])\n",
    "print (train.targets[0])\n",
    "\n",
    "print (train.inputs.shape)\n",
    "print (train.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97cf30-6233-4f85-8f00-6c7f5f0797de",
   "metadata": {},
   "source": [
    "The Morgan fingerprints are 2048 bits long and the targets are real numbers.\n",
    "\n",
    "Let's see if there are some columns containg only zeros, so that we can get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd91defe-c8af-47ec-b553-631aeb65e831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(1578, 2048)\n"
     ]
    }
   ],
   "source": [
    "train_features_clean = train.inputs[:,~np.all(train.inputs == 0, axis = 0)]\n",
    "print (train_features_clean)\n",
    "print (train_features_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10588a68-9eab-4723-80be-d78823bf3684",
   "metadata": {},
   "source": [
    "The size didn't change.\n",
    "\n",
    "Now we will plot the histogram of the target values from the training set. As we can see, it is quite far from the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce948e8b-c254-4586-a2d5-ca58caa7357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.targets, bins=30)\n",
    "plt.title(\"Train set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbc53a-d97d-48ae-aee9-255f90d7f2bf",
   "metadata": {},
   "source": [
    "Unfortunately, we cannot plot the histogram for the test set, because within Polaris you should not need to access the targets of the test set. So, we cannot transform both sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ecddd-4831-41a0-bdfd-9f76bf5ea1f3",
   "metadata": {},
   "source": [
    "Below is the code for the fitting our data with the Random Forest algorithm, which returns the R2 score. It accepts two hyperparameters: the number of estimators and the max depth of trees as well as the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54dcb7e9-f4cf-4695-bc75-9980212d63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RandomForest_r2(train, test, n_estimators, max_depth, random_state):\n",
    "    model = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, random_state = random_state)\n",
    "    model.fit(train.X, train.y)\n",
    "\n",
    "    y_pred = model.predict(test.X)\n",
    "\n",
    "    results = benchmark1.evaluate(y_pred)\n",
    "\n",
    "    for k, item in enumerate(results.results['Metric']):\n",
    "        if str(item) == 'Metric.r2':\n",
    "            return results, results.results['Score'][k]\n",
    "    return results, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7944d39-8ee0-48c4-9a0a-603163592c51",
   "metadata": {},
   "source": [
    "Here is an example for 30 estimators and max depth of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815c817d-81b6-450a-bc4b-84f32bb900a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 5 0.1141961436623099\n"
     ]
    }
   ],
   "source": [
    "mrf, r2_score_mrf = RandomForest_r2(train, test, 30, 5, 777)\n",
    "print (30, 5, r2_score_mrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12fe48-7228-4e5c-b84f-0848edfb2ca4",
   "metadata": {},
   "source": [
    "It might not be the best result. Therefore, the hyperparameters need to be optimized. Below is a simple genetic algorithm for the optimization of hyperparameters of the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b4f2b2-fd20-482c-a112-43359b82e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_for_RandomForest_r2(train, test, population_size = 16, n_steps = 10, to_print = False):\n",
    "    # hyperparameters\n",
    "    npop = population_size\n",
    "    n_estimators_1 = 15\n",
    "    n_estimators_2 = 150\n",
    "    max_depth_1 = 3\n",
    "    max_depth_2 = 12\n",
    "\n",
    "    estimators_limits = (5, 200)\n",
    "    depth_limits = (2, 20)\n",
    "\n",
    "    # calculate initial score\n",
    "    _, score1 = RandomForest_r2(train, test, n_estimators_1, max_depth_1, 777)\n",
    "    _, score2 = RandomForest_r2(train, test, n_estimators_2, max_depth_2, 777)\n",
    "\n",
    "    best_value = max(score1, score1)\n",
    "    r2_list = list()\n",
    "\n",
    "    if score1 > score2:\n",
    "        r2_list.append((score2, max_depth_2, n_estimators_2))\n",
    "        r2_list.append((score1, max_depth_1, n_estimators_1))\n",
    "    else:\n",
    "        r2_list.append((score1, max_depth_1, n_estimators_1))\n",
    "        r2_list.append((score2, max_depth_2, n_estimators_2))\n",
    "\n",
    "    # start the optimization\n",
    "    for i in range(n_steps):\n",
    "        print('iter %d. reward: %f' % (i, best_value))\n",
    "\n",
    "        pop_estimators = generate_population(n_estimators_1, n_estimators_2, estimators_limits, npop)\n",
    "        pop_depth = generate_population(max_depth_1, max_depth_2, depth_limits, npop)\n",
    "\n",
    "        R = np.zeros(npop)\n",
    "        for j in range(npop):\n",
    "            _, R[j] = RandomForest_r2(train, test, pop_estimators[j], pop_depth[j], 777)\n",
    "            if to_print: print (j, pop_estimators[j], pop_depth[j], R[j])\n",
    "\n",
    "        Z = [(x, y) for _, x, y in sorted(zip(R, pop_estimators, pop_depth), key=lambda pair: pair[0])]\n",
    "\n",
    "        n_estimators_1 = Z[-1][0]\n",
    "        n_estimators_2 = Z[-2][0]\n",
    "\n",
    "        max_depth_1 = Z[-1][1]\n",
    "        max_depth_2 = Z[-2][1]\n",
    "\n",
    "        if np.max(R) > best_value:\n",
    "            best_value = np.max(R)\n",
    "            r2_list.append((best_value, n_estimators_1, max_depth_1))\n",
    "        else:\n",
    "            n_estimators_2 = r2_list[-1][1]\n",
    "            max_depth_2 = r2_list[-1][2]\n",
    "\n",
    "    return best_value, r2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec89bf-03af-4d87-966b-5de760c56eb7",
   "metadata": {},
   "source": [
    "We need to generate a population for the genetic algorithm. We will do it based on two \"parents\" and also randomly apply mutations. If the parents are integers, the population will also consits of integer numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652b0ecc-868d-4d66-8391-03cacedc1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_population(parent1, parent2, limits, npop):\n",
    "    population = []\n",
    "\n",
    "    for k in range(npop):\n",
    "        p = random.random()\n",
    "        mated_val = parent1 * p + parent2 * (1 - p)\n",
    "            \n",
    "        if random.random() < 0.2:\n",
    "            mated_val = mated_val * (0.7 + 0.6 * random.random())\n",
    "                \n",
    "        if mated_val < limits[0]:\n",
    "            mated_val = limits[0]\n",
    "        elif mated_val > limits[1]:\n",
    "            mated_val = limits[1]\n",
    "\n",
    "        if isinstance(parent1, int) and isinstance(parent2, int):\n",
    "            mated_val = int(mated_val)\n",
    "                \n",
    "        child = mated_val\n",
    "\n",
    "        population.append(child)\n",
    "       \n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997965d-1e4d-4ca5-b086-060bc9cbef56",
   "metadata": {},
   "source": [
    "Let's run GA for 10 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025d815e-dd3b-456b-a702-777715823b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. reward: 0.089301\n",
      "iter 1. reward: 0.168687\n",
      "iter 2. reward: 0.172770\n",
      "iter 3. reward: 0.174369\n",
      "iter 4. reward: 0.178748\n",
      "iter 5. reward: 0.183452\n",
      "iter 6. reward: 0.196024\n",
      "iter 7. reward: 0.196024\n",
      "iter 8. reward: 0.201364\n",
      "iter 9. reward: 0.203673\n"
     ]
    }
   ],
   "source": [
    "best_value, r2score_list = GA_for_RandomForest_r2(train, test, to_print = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cdb34a0-3743-4612-8983-4030589ee948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.212156643600252, 67, 20)\n"
     ]
    }
   ],
   "source": [
    "print (r2score_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98aa29f-9861-4c68-a438-028c5a767dc9",
   "metadata": {},
   "source": [
    "Now we rerun `RandomForest_r2` with the optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f506d661-3242-43f5-b966-c705ac0ac5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 20 0.212156643600252\n",
      "name=None description='' tags=[] user_attributes={} owner=None polaris_version='dev' results=  Test set    Target label                      Metric     Score\n",
      "0     test  LOG_SOLUBILITY  Metric.mean_absolute_error  0.456667\n",
      "1     test  LOG_SOLUBILITY   Metric.mean_squared_error  0.427152\n",
      "2     test  LOG_SOLUBILITY                   Metric.r2  0.212157\n",
      "3     test  LOG_SOLUBILITY            Metric.spearmanr  0.415035\n",
      "4     test  LOG_SOLUBILITY             Metric.pearsonr  0.499596\n",
      "5     test  LOG_SOLUBILITY        Metric.explained_var  0.219326 benchmark_name='adme-fang-SOLU-1' benchmark_owner=HubOwner(slug='polaris', external_id='org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu', type='organization') github_url=None paper_url=None contributors=None artifact_id=None benchmark_artifact_id='polaris/adme-fang-solu-1'\n"
     ]
    }
   ],
   "source": [
    "mrf, r2_score_mrf = RandomForest_r2(train, test, r2score_list[-1][1], r2score_list[-1][2], 777)\n",
    "print (r2score_list[-1][1], r2score_list[-1][2], r2_score_mrf)\n",
    "print (mrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd23ad6-1638-4614-9c08-182726cc18ce",
   "metadata": {},
   "source": [
    "Let's now see if we can do better with the Gradient Boosting Decision Trees algorithm. Below is the code for the fitting our data with the Gradient Boosting Decision Trees algorithm, which returns the R2 score. It accepts three hyperparameters: the number of estimators, the max depth of trees and the learning rate as well as the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de39f601-b0a2-468d-b6b5-8d2fecb0619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def GBoost_r2(train, test, n_est, max_d, learn_r, rand_st):\n",
    "    model = GradientBoostingRegressor(n_estimators=n_est, max_depth=max_d, learning_rate=learn_r, random_state=rand_st)\n",
    "    model.fit(train.X, train.y)\n",
    "\n",
    "    y_pred = model.predict(test.X)\n",
    "\n",
    "    results = benchmark1.evaluate(y_pred)\n",
    "\n",
    "    for k, item in enumerate(results.results['Metric']):\n",
    "        if str(item) == 'Metric.r2':\n",
    "            return results, results.results['Score'][k]\n",
    "    return results, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aaf5ba-8fcf-4b0b-98b8-2b0bbaf794d7",
   "metadata": {},
   "source": [
    "Here is an example for 30 estimators, max depth of 5 and learning rate 0.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a555b82e-a749-4804-88dc-e5208e91f813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 5 0.12 0.1909362514113181\n"
     ]
    }
   ],
   "source": [
    "mgb, r2_score_mgb = GBoost_r2(train, test, 30, 5, 0.12, 777)\n",
    "print (30, 5, 0.12, r2_score_mgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89767fdd-1d32-423a-94e3-7b733d977a09",
   "metadata": {},
   "source": [
    "Below is a simple genetic algorithm for the optimization of hyperparameters of the Gradient Boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74593ced-8f65-43af-b190-6861770a3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_for_GBoost_r2(train, test, population_size = 16, n_steps = 10, to_print = False):\n",
    "    # hyperparameters\n",
    "    npop = population_size\n",
    "    n_estimators_1 = 15\n",
    "    n_estimators_2 = 150\n",
    "    max_depth_1 = 3\n",
    "    max_depth_2 = 12\n",
    "    learning_rate_1 = -0.6 # it will be used as an exponent\n",
    "    learning_rate_2 = -1.6 # it will be used as an exponent\n",
    "\n",
    "    estimators_limits = (5, 200)\n",
    "    depth_limits = (2, 20)\n",
    "    learning_rate_limits = (-2.0, 0.0)\n",
    "\n",
    "    # calculate initial score\n",
    "    _, score1 = GBoost_r2(train, test, n_estimators_1, max_depth_1, 10**learning_rate_1, 777)\n",
    "    _, score2 = GBoost_r2(train, test, n_estimators_2, max_depth_2, 10**learning_rate_2, 777)\n",
    "\n",
    "    best_value = max(score1, score1)\n",
    "    r2_list = list()\n",
    "\n",
    "    if score1 > score2:\n",
    "        r2_list.append((score2, max_depth_2, n_estimators_2, learning_rate_2))\n",
    "        r2_list.append((score1, max_depth_1, n_estimators_1, learning_rate_1))\n",
    "    else:\n",
    "        r2_list.append((score1, max_depth_1, n_estimators_1, learning_rate_1))\n",
    "        r2_list.append((score2, max_depth_2, n_estimators_2, learning_rate_2))\n",
    "\n",
    "    # start the optimization\n",
    "    for i in range(n_steps):\n",
    "        print('iter %d. reward: %f' % (i, best_value))\n",
    "\n",
    "        pop_estimators = generate_population(n_estimators_1, n_estimators_2, estimators_limits, npop)\n",
    "        pop_depth = generate_population(max_depth_1, max_depth_2, depth_limits, npop)\n",
    "        pop_learning_rate = generate_population(learning_rate_1, learning_rate_2, learning_rate_limits, npop)\n",
    "\n",
    "        R = np.zeros(npop)\n",
    "        for j in range(npop):\n",
    "            _, R[j] = GBoost_r2(train, test, pop_estimators[j], pop_depth[j], 10**pop_learning_rate[j], 777)\n",
    "            if to_print: print (j, pop_estimators[j], pop_depth[j], 10**pop_learning_rate[j], R[j])\n",
    "\n",
    "        Z = [(x, y, z) for _, x, y, z in sorted(zip(R, pop_estimators, pop_depth, pop_learning_rate), key=lambda pair: pair[0])]\n",
    "\n",
    "        n_estimators_1 = Z[-1][0]\n",
    "        n_estimators_2 = Z[-2][0]\n",
    "\n",
    "        max_depth_1 = Z[-1][1]\n",
    "        max_depth_2 = Z[-2][1]\n",
    "\n",
    "        learning_rate_1 = Z[-1][2]\n",
    "        learning_rate_2 = Z[-2][2]\n",
    "\n",
    "        if np.max(R) > best_value:\n",
    "            best_value = np.max(R)\n",
    "            r2_list.append((best_value, n_estimators_1, max_depth_1, learning_rate_1))\n",
    "        else:\n",
    "            n_estimators_2 = r2_list[-1][1]\n",
    "            max_depth_2 = r2_list[-1][2]\n",
    "            learning_rate_2 = r2_list[-1][3]\n",
    "\n",
    "    return best_value, r2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15294c51-ef82-4a2b-918d-e3da518dadbe",
   "metadata": {},
   "source": [
    "Let's run GA for 10 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7041c9a-12d3-4c85-a3d6-62b395d654cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. reward: 0.138732\n",
      "iter 1. reward: 0.227278\n",
      "iter 2. reward: 0.249996\n",
      "iter 3. reward: 0.249996\n",
      "iter 4. reward: 0.249996\n",
      "iter 5. reward: 0.259216\n",
      "iter 6. reward: 0.265759\n",
      "iter 7. reward: 0.280829\n",
      "iter 8. reward: 0.281360\n",
      "iter 9. reward: 0.281360\n"
     ]
    }
   ],
   "source": [
    "best_value, r2score_list = GA_for_GBoost_r2(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "984565d7-6a55-4cff-8323-e0cd42d24982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.28171813674985613, 138, 8, -0.9990261044933678)\n"
     ]
    }
   ],
   "source": [
    "print (r2score_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d9797-5cc2-40f3-92d9-409ad120c146",
   "metadata": {},
   "source": [
    "Now we rerun `GBoost_r2` with the optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b39e3ae-eaae-4ce8-9375-1b4ee019c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 8 0.10022449935083845 0.28171813674985613\n",
      "name=None description='' tags=[] user_attributes={} owner=None polaris_version='dev' results=  Test set    Target label                      Metric     Score\n",
      "0     test  LOG_SOLUBILITY  Metric.mean_absolute_error  0.437920\n",
      "1     test  LOG_SOLUBILITY   Metric.mean_squared_error  0.389437\n",
      "2     test  LOG_SOLUBILITY                   Metric.r2  0.281718\n",
      "3     test  LOG_SOLUBILITY            Metric.spearmanr  0.491951\n",
      "4     test  LOG_SOLUBILITY             Metric.pearsonr  0.538332\n",
      "5     test  LOG_SOLUBILITY        Metric.explained_var  0.285496 benchmark_name='adme-fang-SOLU-1' benchmark_owner=HubOwner(slug='polaris', external_id='org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu', type='organization') github_url=None paper_url=None contributors=None artifact_id=None benchmark_artifact_id='polaris/adme-fang-solu-1'\n"
     ]
    }
   ],
   "source": [
    "rgb, r2_score_rgb = GBoost_r2(train, test, r2score_list[-1][1], r2score_list[-1][2], 10**r2score_list[-1][3], 777)\n",
    "print (r2score_list[-1][1], r2score_list[-1][2], 10**r2score_list[-1][3], r2_score_rgb)\n",
    "print (rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55cd6b-e778-492d-a9ea-e5a0177e1f64",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The best results for the **Gradient Boosting Decision Trees** algorithm and Morgan fingerprints, **R2 = 0.281718**, are obtained with the following hyperparameters: n_estimators = 138, max_depth = 8, learning_rate = 0.10022449935083845.\n",
    "\n",
    "The best results for the **Random Forest** algorithm and Morgan fingerprints, **R2 = 0.212157**, are obtained with the following hyperparameters: n_estimators = 67, max_depth = 20.\n",
    "\n",
    "So, the Gradient Boosting Decision Trees algorithm is noticeably better than Random Forest.\n",
    "\n",
    "In the next Jypyter notebooks we will explore the performance of other descriptors with the Gradient Boosting Decision Trees algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae3b2c-187d-4022-a430-ccf5b1acb617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
